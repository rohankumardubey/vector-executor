// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: src/proto/expr.proto

package org.apache.spark.sql.execution.serde;

public final class ExprOuterClass {
  private ExprOuterClass() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface ExprOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.spark_expression.Expr)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>.spark.spark_expression.Literal literal = 2;</code>
     * @return Whether the literal field is set.
     */
    boolean hasLiteral();
    /**
     * <code>.spark.spark_expression.Literal literal = 2;</code>
     * @return The literal.
     */
    org.apache.spark.sql.execution.serde.ExprOuterClass.Literal getLiteral();
    /**
     * <code>.spark.spark_expression.Literal literal = 2;</code>
     */
    org.apache.spark.sql.execution.serde.ExprOuterClass.LiteralOrBuilder getLiteralOrBuilder();

    /**
     * <code>.spark.spark_expression.Add add = 3;</code>
     * @return Whether the add field is set.
     */
    boolean hasAdd();
    /**
     * <code>.spark.spark_expression.Add add = 3;</code>
     * @return The add.
     */
    org.apache.spark.sql.execution.serde.ExprOuterClass.Add getAdd();
    /**
     * <code>.spark.spark_expression.Add add = 3;</code>
     */
    org.apache.spark.sql.execution.serde.ExprOuterClass.AddOrBuilder getAddOrBuilder();

    /**
     * <code>.spark.spark_expression.BoundReference bound = 4;</code>
     * @return Whether the bound field is set.
     */
    boolean hasBound();
    /**
     * <code>.spark.spark_expression.BoundReference bound = 4;</code>
     * @return The bound.
     */
    org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference getBound();
    /**
     * <code>.spark.spark_expression.BoundReference bound = 4;</code>
     */
    org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReferenceOrBuilder getBoundOrBuilder();

    public org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.ExprStructCase getExprStructCase();
  }
  /**
   * <pre>
   * The basic message representing a Spark expression.
   * </pre>
   *
   * Protobuf type {@code spark.spark_expression.Expr}
   */
  public static final class Expr extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.spark_expression.Expr)
      ExprOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Expr.newBuilder() to construct.
    private Expr(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Expr() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Expr();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Expr(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 18: {
              org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.Builder subBuilder = null;
              if (exprStructCase_ == 2) {
                subBuilder = ((org.apache.spark.sql.execution.serde.ExprOuterClass.Literal) exprStruct_).toBuilder();
              }
              exprStruct_ =
                  input.readMessage(org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((org.apache.spark.sql.execution.serde.ExprOuterClass.Literal) exprStruct_);
                exprStruct_ = subBuilder.buildPartial();
              }
              exprStructCase_ = 2;
              break;
            }
            case 26: {
              org.apache.spark.sql.execution.serde.ExprOuterClass.Add.Builder subBuilder = null;
              if (exprStructCase_ == 3) {
                subBuilder = ((org.apache.spark.sql.execution.serde.ExprOuterClass.Add) exprStruct_).toBuilder();
              }
              exprStruct_ =
                  input.readMessage(org.apache.spark.sql.execution.serde.ExprOuterClass.Add.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((org.apache.spark.sql.execution.serde.ExprOuterClass.Add) exprStruct_);
                exprStruct_ = subBuilder.buildPartial();
              }
              exprStructCase_ = 3;
              break;
            }
            case 34: {
              org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.Builder subBuilder = null;
              if (exprStructCase_ == 4) {
                subBuilder = ((org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference) exprStruct_).toBuilder();
              }
              exprStruct_ =
                  input.readMessage(org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference) exprStruct_);
                exprStruct_ = subBuilder.buildPartial();
              }
              exprStructCase_ = 4;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Expr_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Expr_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.class, org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder.class);
    }

    private int exprStructCase_ = 0;
    private java.lang.Object exprStruct_;
    public enum ExprStructCase
        implements com.google.protobuf.Internal.EnumLite,
            com.google.protobuf.AbstractMessage.InternalOneOfEnum {
      LITERAL(2),
      ADD(3),
      BOUND(4),
      EXPRSTRUCT_NOT_SET(0);
      private final int value;
      private ExprStructCase(int value) {
        this.value = value;
      }
      /**
       * @param value The number of the enum to look for.
       * @return The enum associated with the given number.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static ExprStructCase valueOf(int value) {
        return forNumber(value);
      }

      public static ExprStructCase forNumber(int value) {
        switch (value) {
          case 2: return LITERAL;
          case 3: return ADD;
          case 4: return BOUND;
          case 0: return EXPRSTRUCT_NOT_SET;
          default: return null;
        }
      }
      public int getNumber() {
        return this.value;
      }
    };

    public ExprStructCase
    getExprStructCase() {
      return ExprStructCase.forNumber(
          exprStructCase_);
    }

    public static final int LITERAL_FIELD_NUMBER = 2;
    /**
     * <code>.spark.spark_expression.Literal literal = 2;</code>
     * @return Whether the literal field is set.
     */
    @java.lang.Override
    public boolean hasLiteral() {
      return exprStructCase_ == 2;
    }
    /**
     * <code>.spark.spark_expression.Literal literal = 2;</code>
     * @return The literal.
     */
    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.Literal getLiteral() {
      if (exprStructCase_ == 2) {
         return (org.apache.spark.sql.execution.serde.ExprOuterClass.Literal) exprStruct_;
      }
      return org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.getDefaultInstance();
    }
    /**
     * <code>.spark.spark_expression.Literal literal = 2;</code>
     */
    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.LiteralOrBuilder getLiteralOrBuilder() {
      if (exprStructCase_ == 2) {
         return (org.apache.spark.sql.execution.serde.ExprOuterClass.Literal) exprStruct_;
      }
      return org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.getDefaultInstance();
    }

    public static final int ADD_FIELD_NUMBER = 3;
    /**
     * <code>.spark.spark_expression.Add add = 3;</code>
     * @return Whether the add field is set.
     */
    @java.lang.Override
    public boolean hasAdd() {
      return exprStructCase_ == 3;
    }
    /**
     * <code>.spark.spark_expression.Add add = 3;</code>
     * @return The add.
     */
    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.Add getAdd() {
      if (exprStructCase_ == 3) {
         return (org.apache.spark.sql.execution.serde.ExprOuterClass.Add) exprStruct_;
      }
      return org.apache.spark.sql.execution.serde.ExprOuterClass.Add.getDefaultInstance();
    }
    /**
     * <code>.spark.spark_expression.Add add = 3;</code>
     */
    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.AddOrBuilder getAddOrBuilder() {
      if (exprStructCase_ == 3) {
         return (org.apache.spark.sql.execution.serde.ExprOuterClass.Add) exprStruct_;
      }
      return org.apache.spark.sql.execution.serde.ExprOuterClass.Add.getDefaultInstance();
    }

    public static final int BOUND_FIELD_NUMBER = 4;
    /**
     * <code>.spark.spark_expression.BoundReference bound = 4;</code>
     * @return Whether the bound field is set.
     */
    @java.lang.Override
    public boolean hasBound() {
      return exprStructCase_ == 4;
    }
    /**
     * <code>.spark.spark_expression.BoundReference bound = 4;</code>
     * @return The bound.
     */
    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference getBound() {
      if (exprStructCase_ == 4) {
         return (org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference) exprStruct_;
      }
      return org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.getDefaultInstance();
    }
    /**
     * <code>.spark.spark_expression.BoundReference bound = 4;</code>
     */
    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReferenceOrBuilder getBoundOrBuilder() {
      if (exprStructCase_ == 4) {
         return (org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference) exprStruct_;
      }
      return org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.getDefaultInstance();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (exprStructCase_ == 2) {
        output.writeMessage(2, (org.apache.spark.sql.execution.serde.ExprOuterClass.Literal) exprStruct_);
      }
      if (exprStructCase_ == 3) {
        output.writeMessage(3, (org.apache.spark.sql.execution.serde.ExprOuterClass.Add) exprStruct_);
      }
      if (exprStructCase_ == 4) {
        output.writeMessage(4, (org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference) exprStruct_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (exprStructCase_ == 2) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, (org.apache.spark.sql.execution.serde.ExprOuterClass.Literal) exprStruct_);
      }
      if (exprStructCase_ == 3) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, (org.apache.spark.sql.execution.serde.ExprOuterClass.Add) exprStruct_);
      }
      if (exprStructCase_ == 4) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, (org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference) exprStruct_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.sql.execution.serde.ExprOuterClass.Expr)) {
        return super.equals(obj);
      }
      org.apache.spark.sql.execution.serde.ExprOuterClass.Expr other = (org.apache.spark.sql.execution.serde.ExprOuterClass.Expr) obj;

      if (!getExprStructCase().equals(other.getExprStructCase())) return false;
      switch (exprStructCase_) {
        case 2:
          if (!getLiteral()
              .equals(other.getLiteral())) return false;
          break;
        case 3:
          if (!getAdd()
              .equals(other.getAdd())) return false;
          break;
        case 4:
          if (!getBound()
              .equals(other.getBound())) return false;
          break;
        case 0:
        default:
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      switch (exprStructCase_) {
        case 2:
          hash = (37 * hash) + LITERAL_FIELD_NUMBER;
          hash = (53 * hash) + getLiteral().hashCode();
          break;
        case 3:
          hash = (37 * hash) + ADD_FIELD_NUMBER;
          hash = (53 * hash) + getAdd().hashCode();
          break;
        case 4:
          hash = (37 * hash) + BOUND_FIELD_NUMBER;
          hash = (53 * hash) + getBound().hashCode();
          break;
        case 0:
        default:
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Expr parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Expr parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Expr parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Expr parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Expr parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Expr parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Expr parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Expr parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Expr parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Expr parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Expr parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Expr parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.sql.execution.serde.ExprOuterClass.Expr prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * The basic message representing a Spark expression.
     * </pre>
     *
     * Protobuf type {@code spark.spark_expression.Expr}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.spark_expression.Expr)
        org.apache.spark.sql.execution.serde.ExprOuterClass.ExprOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Expr_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Expr_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.class, org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder.class);
      }

      // Construct using org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        exprStructCase_ = 0;
        exprStruct_ = null;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Expr_descriptor;
      }

      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Expr getDefaultInstanceForType() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Expr build() {
        org.apache.spark.sql.execution.serde.ExprOuterClass.Expr result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Expr buildPartial() {
        org.apache.spark.sql.execution.serde.ExprOuterClass.Expr result = new org.apache.spark.sql.execution.serde.ExprOuterClass.Expr(this);
        if (exprStructCase_ == 2) {
          if (literalBuilder_ == null) {
            result.exprStruct_ = exprStruct_;
          } else {
            result.exprStruct_ = literalBuilder_.build();
          }
        }
        if (exprStructCase_ == 3) {
          if (addBuilder_ == null) {
            result.exprStruct_ = exprStruct_;
          } else {
            result.exprStruct_ = addBuilder_.build();
          }
        }
        if (exprStructCase_ == 4) {
          if (boundBuilder_ == null) {
            result.exprStruct_ = exprStruct_;
          } else {
            result.exprStruct_ = boundBuilder_.build();
          }
        }
        result.exprStructCase_ = exprStructCase_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.sql.execution.serde.ExprOuterClass.Expr) {
          return mergeFrom((org.apache.spark.sql.execution.serde.ExprOuterClass.Expr)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.sql.execution.serde.ExprOuterClass.Expr other) {
        if (other == org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.getDefaultInstance()) return this;
        switch (other.getExprStructCase()) {
          case LITERAL: {
            mergeLiteral(other.getLiteral());
            break;
          }
          case ADD: {
            mergeAdd(other.getAdd());
            break;
          }
          case BOUND: {
            mergeBound(other.getBound());
            break;
          }
          case EXPRSTRUCT_NOT_SET: {
            break;
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.spark.sql.execution.serde.ExprOuterClass.Expr parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.spark.sql.execution.serde.ExprOuterClass.Expr) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int exprStructCase_ = 0;
      private java.lang.Object exprStruct_;
      public ExprStructCase
          getExprStructCase() {
        return ExprStructCase.forNumber(
            exprStructCase_);
      }

      public Builder clearExprStruct() {
        exprStructCase_ = 0;
        exprStruct_ = null;
        onChanged();
        return this;
      }


      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.execution.serde.ExprOuterClass.Literal, org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.LiteralOrBuilder> literalBuilder_;
      /**
       * <code>.spark.spark_expression.Literal literal = 2;</code>
       * @return Whether the literal field is set.
       */
      @java.lang.Override
      public boolean hasLiteral() {
        return exprStructCase_ == 2;
      }
      /**
       * <code>.spark.spark_expression.Literal literal = 2;</code>
       * @return The literal.
       */
      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Literal getLiteral() {
        if (literalBuilder_ == null) {
          if (exprStructCase_ == 2) {
            return (org.apache.spark.sql.execution.serde.ExprOuterClass.Literal) exprStruct_;
          }
          return org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.getDefaultInstance();
        } else {
          if (exprStructCase_ == 2) {
            return literalBuilder_.getMessage();
          }
          return org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.getDefaultInstance();
        }
      }
      /**
       * <code>.spark.spark_expression.Literal literal = 2;</code>
       */
      public Builder setLiteral(org.apache.spark.sql.execution.serde.ExprOuterClass.Literal value) {
        if (literalBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          exprStruct_ = value;
          onChanged();
        } else {
          literalBuilder_.setMessage(value);
        }
        exprStructCase_ = 2;
        return this;
      }
      /**
       * <code>.spark.spark_expression.Literal literal = 2;</code>
       */
      public Builder setLiteral(
          org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.Builder builderForValue) {
        if (literalBuilder_ == null) {
          exprStruct_ = builderForValue.build();
          onChanged();
        } else {
          literalBuilder_.setMessage(builderForValue.build());
        }
        exprStructCase_ = 2;
        return this;
      }
      /**
       * <code>.spark.spark_expression.Literal literal = 2;</code>
       */
      public Builder mergeLiteral(org.apache.spark.sql.execution.serde.ExprOuterClass.Literal value) {
        if (literalBuilder_ == null) {
          if (exprStructCase_ == 2 &&
              exprStruct_ != org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.getDefaultInstance()) {
            exprStruct_ = org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.newBuilder((org.apache.spark.sql.execution.serde.ExprOuterClass.Literal) exprStruct_)
                .mergeFrom(value).buildPartial();
          } else {
            exprStruct_ = value;
          }
          onChanged();
        } else {
          if (exprStructCase_ == 2) {
            literalBuilder_.mergeFrom(value);
          }
          literalBuilder_.setMessage(value);
        }
        exprStructCase_ = 2;
        return this;
      }
      /**
       * <code>.spark.spark_expression.Literal literal = 2;</code>
       */
      public Builder clearLiteral() {
        if (literalBuilder_ == null) {
          if (exprStructCase_ == 2) {
            exprStructCase_ = 0;
            exprStruct_ = null;
            onChanged();
          }
        } else {
          if (exprStructCase_ == 2) {
            exprStructCase_ = 0;
            exprStruct_ = null;
          }
          literalBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>.spark.spark_expression.Literal literal = 2;</code>
       */
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.Builder getLiteralBuilder() {
        return getLiteralFieldBuilder().getBuilder();
      }
      /**
       * <code>.spark.spark_expression.Literal literal = 2;</code>
       */
      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.LiteralOrBuilder getLiteralOrBuilder() {
        if ((exprStructCase_ == 2) && (literalBuilder_ != null)) {
          return literalBuilder_.getMessageOrBuilder();
        } else {
          if (exprStructCase_ == 2) {
            return (org.apache.spark.sql.execution.serde.ExprOuterClass.Literal) exprStruct_;
          }
          return org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.getDefaultInstance();
        }
      }
      /**
       * <code>.spark.spark_expression.Literal literal = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.execution.serde.ExprOuterClass.Literal, org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.LiteralOrBuilder> 
          getLiteralFieldBuilder() {
        if (literalBuilder_ == null) {
          if (!(exprStructCase_ == 2)) {
            exprStruct_ = org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.getDefaultInstance();
          }
          literalBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.spark.sql.execution.serde.ExprOuterClass.Literal, org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.LiteralOrBuilder>(
                  (org.apache.spark.sql.execution.serde.ExprOuterClass.Literal) exprStruct_,
                  getParentForChildren(),
                  isClean());
          exprStruct_ = null;
        }
        exprStructCase_ = 2;
        onChanged();;
        return literalBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.execution.serde.ExprOuterClass.Add, org.apache.spark.sql.execution.serde.ExprOuterClass.Add.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.AddOrBuilder> addBuilder_;
      /**
       * <code>.spark.spark_expression.Add add = 3;</code>
       * @return Whether the add field is set.
       */
      @java.lang.Override
      public boolean hasAdd() {
        return exprStructCase_ == 3;
      }
      /**
       * <code>.spark.spark_expression.Add add = 3;</code>
       * @return The add.
       */
      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Add getAdd() {
        if (addBuilder_ == null) {
          if (exprStructCase_ == 3) {
            return (org.apache.spark.sql.execution.serde.ExprOuterClass.Add) exprStruct_;
          }
          return org.apache.spark.sql.execution.serde.ExprOuterClass.Add.getDefaultInstance();
        } else {
          if (exprStructCase_ == 3) {
            return addBuilder_.getMessage();
          }
          return org.apache.spark.sql.execution.serde.ExprOuterClass.Add.getDefaultInstance();
        }
      }
      /**
       * <code>.spark.spark_expression.Add add = 3;</code>
       */
      public Builder setAdd(org.apache.spark.sql.execution.serde.ExprOuterClass.Add value) {
        if (addBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          exprStruct_ = value;
          onChanged();
        } else {
          addBuilder_.setMessage(value);
        }
        exprStructCase_ = 3;
        return this;
      }
      /**
       * <code>.spark.spark_expression.Add add = 3;</code>
       */
      public Builder setAdd(
          org.apache.spark.sql.execution.serde.ExprOuterClass.Add.Builder builderForValue) {
        if (addBuilder_ == null) {
          exprStruct_ = builderForValue.build();
          onChanged();
        } else {
          addBuilder_.setMessage(builderForValue.build());
        }
        exprStructCase_ = 3;
        return this;
      }
      /**
       * <code>.spark.spark_expression.Add add = 3;</code>
       */
      public Builder mergeAdd(org.apache.spark.sql.execution.serde.ExprOuterClass.Add value) {
        if (addBuilder_ == null) {
          if (exprStructCase_ == 3 &&
              exprStruct_ != org.apache.spark.sql.execution.serde.ExprOuterClass.Add.getDefaultInstance()) {
            exprStruct_ = org.apache.spark.sql.execution.serde.ExprOuterClass.Add.newBuilder((org.apache.spark.sql.execution.serde.ExprOuterClass.Add) exprStruct_)
                .mergeFrom(value).buildPartial();
          } else {
            exprStruct_ = value;
          }
          onChanged();
        } else {
          if (exprStructCase_ == 3) {
            addBuilder_.mergeFrom(value);
          }
          addBuilder_.setMessage(value);
        }
        exprStructCase_ = 3;
        return this;
      }
      /**
       * <code>.spark.spark_expression.Add add = 3;</code>
       */
      public Builder clearAdd() {
        if (addBuilder_ == null) {
          if (exprStructCase_ == 3) {
            exprStructCase_ = 0;
            exprStruct_ = null;
            onChanged();
          }
        } else {
          if (exprStructCase_ == 3) {
            exprStructCase_ = 0;
            exprStruct_ = null;
          }
          addBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>.spark.spark_expression.Add add = 3;</code>
       */
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Add.Builder getAddBuilder() {
        return getAddFieldBuilder().getBuilder();
      }
      /**
       * <code>.spark.spark_expression.Add add = 3;</code>
       */
      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.AddOrBuilder getAddOrBuilder() {
        if ((exprStructCase_ == 3) && (addBuilder_ != null)) {
          return addBuilder_.getMessageOrBuilder();
        } else {
          if (exprStructCase_ == 3) {
            return (org.apache.spark.sql.execution.serde.ExprOuterClass.Add) exprStruct_;
          }
          return org.apache.spark.sql.execution.serde.ExprOuterClass.Add.getDefaultInstance();
        }
      }
      /**
       * <code>.spark.spark_expression.Add add = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.execution.serde.ExprOuterClass.Add, org.apache.spark.sql.execution.serde.ExprOuterClass.Add.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.AddOrBuilder> 
          getAddFieldBuilder() {
        if (addBuilder_ == null) {
          if (!(exprStructCase_ == 3)) {
            exprStruct_ = org.apache.spark.sql.execution.serde.ExprOuterClass.Add.getDefaultInstance();
          }
          addBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.spark.sql.execution.serde.ExprOuterClass.Add, org.apache.spark.sql.execution.serde.ExprOuterClass.Add.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.AddOrBuilder>(
                  (org.apache.spark.sql.execution.serde.ExprOuterClass.Add) exprStruct_,
                  getParentForChildren(),
                  isClean());
          exprStruct_ = null;
        }
        exprStructCase_ = 3;
        onChanged();;
        return addBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference, org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReferenceOrBuilder> boundBuilder_;
      /**
       * <code>.spark.spark_expression.BoundReference bound = 4;</code>
       * @return Whether the bound field is set.
       */
      @java.lang.Override
      public boolean hasBound() {
        return exprStructCase_ == 4;
      }
      /**
       * <code>.spark.spark_expression.BoundReference bound = 4;</code>
       * @return The bound.
       */
      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference getBound() {
        if (boundBuilder_ == null) {
          if (exprStructCase_ == 4) {
            return (org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference) exprStruct_;
          }
          return org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.getDefaultInstance();
        } else {
          if (exprStructCase_ == 4) {
            return boundBuilder_.getMessage();
          }
          return org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.getDefaultInstance();
        }
      }
      /**
       * <code>.spark.spark_expression.BoundReference bound = 4;</code>
       */
      public Builder setBound(org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference value) {
        if (boundBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          exprStruct_ = value;
          onChanged();
        } else {
          boundBuilder_.setMessage(value);
        }
        exprStructCase_ = 4;
        return this;
      }
      /**
       * <code>.spark.spark_expression.BoundReference bound = 4;</code>
       */
      public Builder setBound(
          org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.Builder builderForValue) {
        if (boundBuilder_ == null) {
          exprStruct_ = builderForValue.build();
          onChanged();
        } else {
          boundBuilder_.setMessage(builderForValue.build());
        }
        exprStructCase_ = 4;
        return this;
      }
      /**
       * <code>.spark.spark_expression.BoundReference bound = 4;</code>
       */
      public Builder mergeBound(org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference value) {
        if (boundBuilder_ == null) {
          if (exprStructCase_ == 4 &&
              exprStruct_ != org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.getDefaultInstance()) {
            exprStruct_ = org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.newBuilder((org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference) exprStruct_)
                .mergeFrom(value).buildPartial();
          } else {
            exprStruct_ = value;
          }
          onChanged();
        } else {
          if (exprStructCase_ == 4) {
            boundBuilder_.mergeFrom(value);
          }
          boundBuilder_.setMessage(value);
        }
        exprStructCase_ = 4;
        return this;
      }
      /**
       * <code>.spark.spark_expression.BoundReference bound = 4;</code>
       */
      public Builder clearBound() {
        if (boundBuilder_ == null) {
          if (exprStructCase_ == 4) {
            exprStructCase_ = 0;
            exprStruct_ = null;
            onChanged();
          }
        } else {
          if (exprStructCase_ == 4) {
            exprStructCase_ = 0;
            exprStruct_ = null;
          }
          boundBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>.spark.spark_expression.BoundReference bound = 4;</code>
       */
      public org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.Builder getBoundBuilder() {
        return getBoundFieldBuilder().getBuilder();
      }
      /**
       * <code>.spark.spark_expression.BoundReference bound = 4;</code>
       */
      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReferenceOrBuilder getBoundOrBuilder() {
        if ((exprStructCase_ == 4) && (boundBuilder_ != null)) {
          return boundBuilder_.getMessageOrBuilder();
        } else {
          if (exprStructCase_ == 4) {
            return (org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference) exprStruct_;
          }
          return org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.getDefaultInstance();
        }
      }
      /**
       * <code>.spark.spark_expression.BoundReference bound = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference, org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReferenceOrBuilder> 
          getBoundFieldBuilder() {
        if (boundBuilder_ == null) {
          if (!(exprStructCase_ == 4)) {
            exprStruct_ = org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.getDefaultInstance();
          }
          boundBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference, org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReferenceOrBuilder>(
                  (org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference) exprStruct_,
                  getParentForChildren(),
                  isClean());
          exprStruct_ = null;
        }
        exprStructCase_ = 4;
        onChanged();;
        return boundBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.spark_expression.Expr)
    }

    // @@protoc_insertion_point(class_scope:spark.spark_expression.Expr)
    private static final org.apache.spark.sql.execution.serde.ExprOuterClass.Expr DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.sql.execution.serde.ExprOuterClass.Expr();
    }

    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Expr getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Expr>
        PARSER = new com.google.protobuf.AbstractParser<Expr>() {
      @java.lang.Override
      public Expr parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Expr(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Expr> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Expr> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.Expr getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface LiteralOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.spark_expression.Literal)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>bool bool_val = 1;</code>
     * @return Whether the boolVal field is set.
     */
    boolean hasBoolVal();
    /**
     * <code>bool bool_val = 1;</code>
     * @return The boolVal.
     */
    boolean getBoolVal();

    /**
     * <code>int32 int_val = 2;</code>
     * @return Whether the intVal field is set.
     */
    boolean hasIntVal();
    /**
     * <code>int32 int_val = 2;</code>
     * @return The intVal.
     */
    int getIntVal();

    /**
     * <code>int64 long_val = 3;</code>
     * @return Whether the longVal field is set.
     */
    boolean hasLongVal();
    /**
     * <code>int64 long_val = 3;</code>
     * @return The longVal.
     */
    long getLongVal();

    /**
     * <code>float float_val = 4;</code>
     * @return Whether the floatVal field is set.
     */
    boolean hasFloatVal();
    /**
     * <code>float float_val = 4;</code>
     * @return The floatVal.
     */
    float getFloatVal();

    /**
     * <code>double double_val = 5;</code>
     * @return Whether the doubleVal field is set.
     */
    boolean hasDoubleVal();
    /**
     * <code>double double_val = 5;</code>
     * @return The doubleVal.
     */
    double getDoubleVal();

    /**
     * <code>string string_val = 6;</code>
     * @return Whether the stringVal field is set.
     */
    boolean hasStringVal();
    /**
     * <code>string string_val = 6;</code>
     * @return The stringVal.
     */
    java.lang.String getStringVal();
    /**
     * <code>string string_val = 6;</code>
     * @return The bytes for stringVal.
     */
    com.google.protobuf.ByteString
        getStringValBytes();

    /**
     * <code>bytes bytes_val = 7;</code>
     * @return Whether the bytesVal field is set.
     */
    boolean hasBytesVal();
    /**
     * <code>bytes bytes_val = 7;</code>
     * @return The bytesVal.
     */
    com.google.protobuf.ByteString getBytesVal();

    public org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.ValueCase getValueCase();
  }
  /**
   * Protobuf type {@code spark.spark_expression.Literal}
   */
  public static final class Literal extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.spark_expression.Literal)
      LiteralOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Literal.newBuilder() to construct.
    private Literal(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Literal() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Literal();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Literal(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              valueCase_ = 1;
              value_ = input.readBool();
              break;
            }
            case 16: {
              valueCase_ = 2;
              value_ = input.readInt32();
              break;
            }
            case 24: {
              valueCase_ = 3;
              value_ = input.readInt64();
              break;
            }
            case 37: {
              valueCase_ = 4;
              value_ = input.readFloat();
              break;
            }
            case 41: {
              valueCase_ = 5;
              value_ = input.readDouble();
              break;
            }
            case 50: {
              java.lang.String s = input.readStringRequireUtf8();
              valueCase_ = 6;
              value_ = s;
              break;
            }
            case 58: {
              valueCase_ = 7;
              value_ = input.readBytes();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Literal_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Literal_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.class, org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.Builder.class);
    }

    private int valueCase_ = 0;
    private java.lang.Object value_;
    public enum ValueCase
        implements com.google.protobuf.Internal.EnumLite,
            com.google.protobuf.AbstractMessage.InternalOneOfEnum {
      BOOL_VAL(1),
      INT_VAL(2),
      LONG_VAL(3),
      FLOAT_VAL(4),
      DOUBLE_VAL(5),
      STRING_VAL(6),
      BYTES_VAL(7),
      VALUE_NOT_SET(0);
      private final int value;
      private ValueCase(int value) {
        this.value = value;
      }
      /**
       * @param value The number of the enum to look for.
       * @return The enum associated with the given number.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static ValueCase valueOf(int value) {
        return forNumber(value);
      }

      public static ValueCase forNumber(int value) {
        switch (value) {
          case 1: return BOOL_VAL;
          case 2: return INT_VAL;
          case 3: return LONG_VAL;
          case 4: return FLOAT_VAL;
          case 5: return DOUBLE_VAL;
          case 6: return STRING_VAL;
          case 7: return BYTES_VAL;
          case 0: return VALUE_NOT_SET;
          default: return null;
        }
      }
      public int getNumber() {
        return this.value;
      }
    };

    public ValueCase
    getValueCase() {
      return ValueCase.forNumber(
          valueCase_);
    }

    public static final int BOOL_VAL_FIELD_NUMBER = 1;
    /**
     * <code>bool bool_val = 1;</code>
     * @return Whether the boolVal field is set.
     */
    @java.lang.Override
    public boolean hasBoolVal() {
      return valueCase_ == 1;
    }
    /**
     * <code>bool bool_val = 1;</code>
     * @return The boolVal.
     */
    @java.lang.Override
    public boolean getBoolVal() {
      if (valueCase_ == 1) {
        return (java.lang.Boolean) value_;
      }
      return false;
    }

    public static final int INT_VAL_FIELD_NUMBER = 2;
    /**
     * <code>int32 int_val = 2;</code>
     * @return Whether the intVal field is set.
     */
    @java.lang.Override
    public boolean hasIntVal() {
      return valueCase_ == 2;
    }
    /**
     * <code>int32 int_val = 2;</code>
     * @return The intVal.
     */
    @java.lang.Override
    public int getIntVal() {
      if (valueCase_ == 2) {
        return (java.lang.Integer) value_;
      }
      return 0;
    }

    public static final int LONG_VAL_FIELD_NUMBER = 3;
    /**
     * <code>int64 long_val = 3;</code>
     * @return Whether the longVal field is set.
     */
    @java.lang.Override
    public boolean hasLongVal() {
      return valueCase_ == 3;
    }
    /**
     * <code>int64 long_val = 3;</code>
     * @return The longVal.
     */
    @java.lang.Override
    public long getLongVal() {
      if (valueCase_ == 3) {
        return (java.lang.Long) value_;
      }
      return 0L;
    }

    public static final int FLOAT_VAL_FIELD_NUMBER = 4;
    /**
     * <code>float float_val = 4;</code>
     * @return Whether the floatVal field is set.
     */
    @java.lang.Override
    public boolean hasFloatVal() {
      return valueCase_ == 4;
    }
    /**
     * <code>float float_val = 4;</code>
     * @return The floatVal.
     */
    @java.lang.Override
    public float getFloatVal() {
      if (valueCase_ == 4) {
        return (java.lang.Float) value_;
      }
      return 0F;
    }

    public static final int DOUBLE_VAL_FIELD_NUMBER = 5;
    /**
     * <code>double double_val = 5;</code>
     * @return Whether the doubleVal field is set.
     */
    @java.lang.Override
    public boolean hasDoubleVal() {
      return valueCase_ == 5;
    }
    /**
     * <code>double double_val = 5;</code>
     * @return The doubleVal.
     */
    @java.lang.Override
    public double getDoubleVal() {
      if (valueCase_ == 5) {
        return (java.lang.Double) value_;
      }
      return 0D;
    }

    public static final int STRING_VAL_FIELD_NUMBER = 6;
    /**
     * <code>string string_val = 6;</code>
     * @return Whether the stringVal field is set.
     */
    public boolean hasStringVal() {
      return valueCase_ == 6;
    }
    /**
     * <code>string string_val = 6;</code>
     * @return The stringVal.
     */
    public java.lang.String getStringVal() {
      java.lang.Object ref = "";
      if (valueCase_ == 6) {
        ref = value_;
      }
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (valueCase_ == 6) {
          value_ = s;
        }
        return s;
      }
    }
    /**
     * <code>string string_val = 6;</code>
     * @return The bytes for stringVal.
     */
    public com.google.protobuf.ByteString
        getStringValBytes() {
      java.lang.Object ref = "";
      if (valueCase_ == 6) {
        ref = value_;
      }
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        if (valueCase_ == 6) {
          value_ = b;
        }
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int BYTES_VAL_FIELD_NUMBER = 7;
    /**
     * <code>bytes bytes_val = 7;</code>
     * @return Whether the bytesVal field is set.
     */
    @java.lang.Override
    public boolean hasBytesVal() {
      return valueCase_ == 7;
    }
    /**
     * <code>bytes bytes_val = 7;</code>
     * @return The bytesVal.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString getBytesVal() {
      if (valueCase_ == 7) {
        return (com.google.protobuf.ByteString) value_;
      }
      return com.google.protobuf.ByteString.EMPTY;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (valueCase_ == 1) {
        output.writeBool(
            1, (boolean)((java.lang.Boolean) value_));
      }
      if (valueCase_ == 2) {
        output.writeInt32(
            2, (int)((java.lang.Integer) value_));
      }
      if (valueCase_ == 3) {
        output.writeInt64(
            3, (long)((java.lang.Long) value_));
      }
      if (valueCase_ == 4) {
        output.writeFloat(
            4, (float)((java.lang.Float) value_));
      }
      if (valueCase_ == 5) {
        output.writeDouble(
            5, (double)((java.lang.Double) value_));
      }
      if (valueCase_ == 6) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 6, value_);
      }
      if (valueCase_ == 7) {
        output.writeBytes(
            7, (com.google.protobuf.ByteString) value_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (valueCase_ == 1) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(
              1, (boolean)((java.lang.Boolean) value_));
      }
      if (valueCase_ == 2) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(
              2, (int)((java.lang.Integer) value_));
      }
      if (valueCase_ == 3) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(
              3, (long)((java.lang.Long) value_));
      }
      if (valueCase_ == 4) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(
              4, (float)((java.lang.Float) value_));
      }
      if (valueCase_ == 5) {
        size += com.google.protobuf.CodedOutputStream
          .computeDoubleSize(
              5, (double)((java.lang.Double) value_));
      }
      if (valueCase_ == 6) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, value_);
      }
      if (valueCase_ == 7) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(
              7, (com.google.protobuf.ByteString) value_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.sql.execution.serde.ExprOuterClass.Literal)) {
        return super.equals(obj);
      }
      org.apache.spark.sql.execution.serde.ExprOuterClass.Literal other = (org.apache.spark.sql.execution.serde.ExprOuterClass.Literal) obj;

      if (!getValueCase().equals(other.getValueCase())) return false;
      switch (valueCase_) {
        case 1:
          if (getBoolVal()
              != other.getBoolVal()) return false;
          break;
        case 2:
          if (getIntVal()
              != other.getIntVal()) return false;
          break;
        case 3:
          if (getLongVal()
              != other.getLongVal()) return false;
          break;
        case 4:
          if (java.lang.Float.floatToIntBits(getFloatVal())
              != java.lang.Float.floatToIntBits(
                  other.getFloatVal())) return false;
          break;
        case 5:
          if (java.lang.Double.doubleToLongBits(getDoubleVal())
              != java.lang.Double.doubleToLongBits(
                  other.getDoubleVal())) return false;
          break;
        case 6:
          if (!getStringVal()
              .equals(other.getStringVal())) return false;
          break;
        case 7:
          if (!getBytesVal()
              .equals(other.getBytesVal())) return false;
          break;
        case 0:
        default:
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      switch (valueCase_) {
        case 1:
          hash = (37 * hash) + BOOL_VAL_FIELD_NUMBER;
          hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
              getBoolVal());
          break;
        case 2:
          hash = (37 * hash) + INT_VAL_FIELD_NUMBER;
          hash = (53 * hash) + getIntVal();
          break;
        case 3:
          hash = (37 * hash) + LONG_VAL_FIELD_NUMBER;
          hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
              getLongVal());
          break;
        case 4:
          hash = (37 * hash) + FLOAT_VAL_FIELD_NUMBER;
          hash = (53 * hash) + java.lang.Float.floatToIntBits(
              getFloatVal());
          break;
        case 5:
          hash = (37 * hash) + DOUBLE_VAL_FIELD_NUMBER;
          hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
              java.lang.Double.doubleToLongBits(getDoubleVal()));
          break;
        case 6:
          hash = (37 * hash) + STRING_VAL_FIELD_NUMBER;
          hash = (53 * hash) + getStringVal().hashCode();
          break;
        case 7:
          hash = (37 * hash) + BYTES_VAL_FIELD_NUMBER;
          hash = (53 * hash) + getBytesVal().hashCode();
          break;
        case 0:
        default:
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Literal parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Literal parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Literal parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Literal parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Literal parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Literal parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Literal parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Literal parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Literal parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Literal parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Literal parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Literal parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.sql.execution.serde.ExprOuterClass.Literal prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.spark_expression.Literal}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.spark_expression.Literal)
        org.apache.spark.sql.execution.serde.ExprOuterClass.LiteralOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Literal_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Literal_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.class, org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.Builder.class);
      }

      // Construct using org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        valueCase_ = 0;
        value_ = null;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Literal_descriptor;
      }

      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Literal getDefaultInstanceForType() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Literal build() {
        org.apache.spark.sql.execution.serde.ExprOuterClass.Literal result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Literal buildPartial() {
        org.apache.spark.sql.execution.serde.ExprOuterClass.Literal result = new org.apache.spark.sql.execution.serde.ExprOuterClass.Literal(this);
        if (valueCase_ == 1) {
          result.value_ = value_;
        }
        if (valueCase_ == 2) {
          result.value_ = value_;
        }
        if (valueCase_ == 3) {
          result.value_ = value_;
        }
        if (valueCase_ == 4) {
          result.value_ = value_;
        }
        if (valueCase_ == 5) {
          result.value_ = value_;
        }
        if (valueCase_ == 6) {
          result.value_ = value_;
        }
        if (valueCase_ == 7) {
          result.value_ = value_;
        }
        result.valueCase_ = valueCase_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.sql.execution.serde.ExprOuterClass.Literal) {
          return mergeFrom((org.apache.spark.sql.execution.serde.ExprOuterClass.Literal)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.sql.execution.serde.ExprOuterClass.Literal other) {
        if (other == org.apache.spark.sql.execution.serde.ExprOuterClass.Literal.getDefaultInstance()) return this;
        switch (other.getValueCase()) {
          case BOOL_VAL: {
            setBoolVal(other.getBoolVal());
            break;
          }
          case INT_VAL: {
            setIntVal(other.getIntVal());
            break;
          }
          case LONG_VAL: {
            setLongVal(other.getLongVal());
            break;
          }
          case FLOAT_VAL: {
            setFloatVal(other.getFloatVal());
            break;
          }
          case DOUBLE_VAL: {
            setDoubleVal(other.getDoubleVal());
            break;
          }
          case STRING_VAL: {
            valueCase_ = 6;
            value_ = other.value_;
            onChanged();
            break;
          }
          case BYTES_VAL: {
            setBytesVal(other.getBytesVal());
            break;
          }
          case VALUE_NOT_SET: {
            break;
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.spark.sql.execution.serde.ExprOuterClass.Literal parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.spark.sql.execution.serde.ExprOuterClass.Literal) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int valueCase_ = 0;
      private java.lang.Object value_;
      public ValueCase
          getValueCase() {
        return ValueCase.forNumber(
            valueCase_);
      }

      public Builder clearValue() {
        valueCase_ = 0;
        value_ = null;
        onChanged();
        return this;
      }


      /**
       * <code>bool bool_val = 1;</code>
       * @return Whether the boolVal field is set.
       */
      public boolean hasBoolVal() {
        return valueCase_ == 1;
      }
      /**
       * <code>bool bool_val = 1;</code>
       * @return The boolVal.
       */
      public boolean getBoolVal() {
        if (valueCase_ == 1) {
          return (java.lang.Boolean) value_;
        }
        return false;
      }
      /**
       * <code>bool bool_val = 1;</code>
       * @param value The boolVal to set.
       * @return This builder for chaining.
       */
      public Builder setBoolVal(boolean value) {
        valueCase_ = 1;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>bool bool_val = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearBoolVal() {
        if (valueCase_ == 1) {
          valueCase_ = 0;
          value_ = null;
          onChanged();
        }
        return this;
      }

      /**
       * <code>int32 int_val = 2;</code>
       * @return Whether the intVal field is set.
       */
      public boolean hasIntVal() {
        return valueCase_ == 2;
      }
      /**
       * <code>int32 int_val = 2;</code>
       * @return The intVal.
       */
      public int getIntVal() {
        if (valueCase_ == 2) {
          return (java.lang.Integer) value_;
        }
        return 0;
      }
      /**
       * <code>int32 int_val = 2;</code>
       * @param value The intVal to set.
       * @return This builder for chaining.
       */
      public Builder setIntVal(int value) {
        valueCase_ = 2;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>int32 int_val = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearIntVal() {
        if (valueCase_ == 2) {
          valueCase_ = 0;
          value_ = null;
          onChanged();
        }
        return this;
      }

      /**
       * <code>int64 long_val = 3;</code>
       * @return Whether the longVal field is set.
       */
      public boolean hasLongVal() {
        return valueCase_ == 3;
      }
      /**
       * <code>int64 long_val = 3;</code>
       * @return The longVal.
       */
      public long getLongVal() {
        if (valueCase_ == 3) {
          return (java.lang.Long) value_;
        }
        return 0L;
      }
      /**
       * <code>int64 long_val = 3;</code>
       * @param value The longVal to set.
       * @return This builder for chaining.
       */
      public Builder setLongVal(long value) {
        valueCase_ = 3;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>int64 long_val = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearLongVal() {
        if (valueCase_ == 3) {
          valueCase_ = 0;
          value_ = null;
          onChanged();
        }
        return this;
      }

      /**
       * <code>float float_val = 4;</code>
       * @return Whether the floatVal field is set.
       */
      public boolean hasFloatVal() {
        return valueCase_ == 4;
      }
      /**
       * <code>float float_val = 4;</code>
       * @return The floatVal.
       */
      public float getFloatVal() {
        if (valueCase_ == 4) {
          return (java.lang.Float) value_;
        }
        return 0F;
      }
      /**
       * <code>float float_val = 4;</code>
       * @param value The floatVal to set.
       * @return This builder for chaining.
       */
      public Builder setFloatVal(float value) {
        valueCase_ = 4;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>float float_val = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearFloatVal() {
        if (valueCase_ == 4) {
          valueCase_ = 0;
          value_ = null;
          onChanged();
        }
        return this;
      }

      /**
       * <code>double double_val = 5;</code>
       * @return Whether the doubleVal field is set.
       */
      public boolean hasDoubleVal() {
        return valueCase_ == 5;
      }
      /**
       * <code>double double_val = 5;</code>
       * @return The doubleVal.
       */
      public double getDoubleVal() {
        if (valueCase_ == 5) {
          return (java.lang.Double) value_;
        }
        return 0D;
      }
      /**
       * <code>double double_val = 5;</code>
       * @param value The doubleVal to set.
       * @return This builder for chaining.
       */
      public Builder setDoubleVal(double value) {
        valueCase_ = 5;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>double double_val = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearDoubleVal() {
        if (valueCase_ == 5) {
          valueCase_ = 0;
          value_ = null;
          onChanged();
        }
        return this;
      }

      /**
       * <code>string string_val = 6;</code>
       * @return Whether the stringVal field is set.
       */
      @java.lang.Override
      public boolean hasStringVal() {
        return valueCase_ == 6;
      }
      /**
       * <code>string string_val = 6;</code>
       * @return The stringVal.
       */
      @java.lang.Override
      public java.lang.String getStringVal() {
        java.lang.Object ref = "";
        if (valueCase_ == 6) {
          ref = value_;
        }
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (valueCase_ == 6) {
            value_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>string string_val = 6;</code>
       * @return The bytes for stringVal.
       */
      @java.lang.Override
      public com.google.protobuf.ByteString
          getStringValBytes() {
        java.lang.Object ref = "";
        if (valueCase_ == 6) {
          ref = value_;
        }
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          if (valueCase_ == 6) {
            value_ = b;
          }
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>string string_val = 6;</code>
       * @param value The stringVal to set.
       * @return This builder for chaining.
       */
      public Builder setStringVal(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  valueCase_ = 6;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>string string_val = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearStringVal() {
        if (valueCase_ == 6) {
          valueCase_ = 0;
          value_ = null;
          onChanged();
        }
        return this;
      }
      /**
       * <code>string string_val = 6;</code>
       * @param value The bytes for stringVal to set.
       * @return This builder for chaining.
       */
      public Builder setStringValBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        valueCase_ = 6;
        value_ = value;
        onChanged();
        return this;
      }

      /**
       * <code>bytes bytes_val = 7;</code>
       * @return Whether the bytesVal field is set.
       */
      public boolean hasBytesVal() {
        return valueCase_ == 7;
      }
      /**
       * <code>bytes bytes_val = 7;</code>
       * @return The bytesVal.
       */
      public com.google.protobuf.ByteString getBytesVal() {
        if (valueCase_ == 7) {
          return (com.google.protobuf.ByteString) value_;
        }
        return com.google.protobuf.ByteString.EMPTY;
      }
      /**
       * <code>bytes bytes_val = 7;</code>
       * @param value The bytesVal to set.
       * @return This builder for chaining.
       */
      public Builder setBytesVal(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  valueCase_ = 7;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>bytes bytes_val = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearBytesVal() {
        if (valueCase_ == 7) {
          valueCase_ = 0;
          value_ = null;
          onChanged();
        }
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.spark_expression.Literal)
    }

    // @@protoc_insertion_point(class_scope:spark.spark_expression.Literal)
    private static final org.apache.spark.sql.execution.serde.ExprOuterClass.Literal DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.sql.execution.serde.ExprOuterClass.Literal();
    }

    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Literal getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Literal>
        PARSER = new com.google.protobuf.AbstractParser<Literal>() {
      @java.lang.Override
      public Literal parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Literal(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Literal> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Literal> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.Literal getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface AddOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.spark_expression.Add)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>.spark.spark_expression.Expr left = 1;</code>
     * @return Whether the left field is set.
     */
    boolean hasLeft();
    /**
     * <code>.spark.spark_expression.Expr left = 1;</code>
     * @return The left.
     */
    org.apache.spark.sql.execution.serde.ExprOuterClass.Expr getLeft();
    /**
     * <code>.spark.spark_expression.Expr left = 1;</code>
     */
    org.apache.spark.sql.execution.serde.ExprOuterClass.ExprOrBuilder getLeftOrBuilder();

    /**
     * <code>.spark.spark_expression.Expr right = 2;</code>
     * @return Whether the right field is set.
     */
    boolean hasRight();
    /**
     * <code>.spark.spark_expression.Expr right = 2;</code>
     * @return The right.
     */
    org.apache.spark.sql.execution.serde.ExprOuterClass.Expr getRight();
    /**
     * <code>.spark.spark_expression.Expr right = 2;</code>
     */
    org.apache.spark.sql.execution.serde.ExprOuterClass.ExprOrBuilder getRightOrBuilder();
  }
  /**
   * Protobuf type {@code spark.spark_expression.Add}
   */
  public static final class Add extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.spark_expression.Add)
      AddOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Add.newBuilder() to construct.
    private Add(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Add() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Add();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Add(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder subBuilder = null;
              if (left_ != null) {
                subBuilder = left_.toBuilder();
              }
              left_ = input.readMessage(org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(left_);
                left_ = subBuilder.buildPartial();
              }

              break;
            }
            case 18: {
              org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder subBuilder = null;
              if (right_ != null) {
                subBuilder = right_.toBuilder();
              }
              right_ = input.readMessage(org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(right_);
                right_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Add_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Add_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.sql.execution.serde.ExprOuterClass.Add.class, org.apache.spark.sql.execution.serde.ExprOuterClass.Add.Builder.class);
    }

    public static final int LEFT_FIELD_NUMBER = 1;
    private org.apache.spark.sql.execution.serde.ExprOuterClass.Expr left_;
    /**
     * <code>.spark.spark_expression.Expr left = 1;</code>
     * @return Whether the left field is set.
     */
    @java.lang.Override
    public boolean hasLeft() {
      return left_ != null;
    }
    /**
     * <code>.spark.spark_expression.Expr left = 1;</code>
     * @return The left.
     */
    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.Expr getLeft() {
      return left_ == null ? org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.getDefaultInstance() : left_;
    }
    /**
     * <code>.spark.spark_expression.Expr left = 1;</code>
     */
    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.ExprOrBuilder getLeftOrBuilder() {
      return getLeft();
    }

    public static final int RIGHT_FIELD_NUMBER = 2;
    private org.apache.spark.sql.execution.serde.ExprOuterClass.Expr right_;
    /**
     * <code>.spark.spark_expression.Expr right = 2;</code>
     * @return Whether the right field is set.
     */
    @java.lang.Override
    public boolean hasRight() {
      return right_ != null;
    }
    /**
     * <code>.spark.spark_expression.Expr right = 2;</code>
     * @return The right.
     */
    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.Expr getRight() {
      return right_ == null ? org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.getDefaultInstance() : right_;
    }
    /**
     * <code>.spark.spark_expression.Expr right = 2;</code>
     */
    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.ExprOrBuilder getRightOrBuilder() {
      return getRight();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (left_ != null) {
        output.writeMessage(1, getLeft());
      }
      if (right_ != null) {
        output.writeMessage(2, getRight());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (left_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getLeft());
      }
      if (right_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getRight());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.sql.execution.serde.ExprOuterClass.Add)) {
        return super.equals(obj);
      }
      org.apache.spark.sql.execution.serde.ExprOuterClass.Add other = (org.apache.spark.sql.execution.serde.ExprOuterClass.Add) obj;

      if (hasLeft() != other.hasLeft()) return false;
      if (hasLeft()) {
        if (!getLeft()
            .equals(other.getLeft())) return false;
      }
      if (hasRight() != other.hasRight()) return false;
      if (hasRight()) {
        if (!getRight()
            .equals(other.getRight())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasLeft()) {
        hash = (37 * hash) + LEFT_FIELD_NUMBER;
        hash = (53 * hash) + getLeft().hashCode();
      }
      if (hasRight()) {
        hash = (37 * hash) + RIGHT_FIELD_NUMBER;
        hash = (53 * hash) + getRight().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Add parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Add parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Add parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Add parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Add parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Add parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Add parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Add parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Add parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Add parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Add parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Add parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.sql.execution.serde.ExprOuterClass.Add prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.spark_expression.Add}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.spark_expression.Add)
        org.apache.spark.sql.execution.serde.ExprOuterClass.AddOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Add_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Add_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.sql.execution.serde.ExprOuterClass.Add.class, org.apache.spark.sql.execution.serde.ExprOuterClass.Add.Builder.class);
      }

      // Construct using org.apache.spark.sql.execution.serde.ExprOuterClass.Add.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (leftBuilder_ == null) {
          left_ = null;
        } else {
          left_ = null;
          leftBuilder_ = null;
        }
        if (rightBuilder_ == null) {
          right_ = null;
        } else {
          right_ = null;
          rightBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_Add_descriptor;
      }

      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Add getDefaultInstanceForType() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.Add.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Add build() {
        org.apache.spark.sql.execution.serde.ExprOuterClass.Add result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Add buildPartial() {
        org.apache.spark.sql.execution.serde.ExprOuterClass.Add result = new org.apache.spark.sql.execution.serde.ExprOuterClass.Add(this);
        if (leftBuilder_ == null) {
          result.left_ = left_;
        } else {
          result.left_ = leftBuilder_.build();
        }
        if (rightBuilder_ == null) {
          result.right_ = right_;
        } else {
          result.right_ = rightBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.sql.execution.serde.ExprOuterClass.Add) {
          return mergeFrom((org.apache.spark.sql.execution.serde.ExprOuterClass.Add)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.sql.execution.serde.ExprOuterClass.Add other) {
        if (other == org.apache.spark.sql.execution.serde.ExprOuterClass.Add.getDefaultInstance()) return this;
        if (other.hasLeft()) {
          mergeLeft(other.getLeft());
        }
        if (other.hasRight()) {
          mergeRight(other.getRight());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.spark.sql.execution.serde.ExprOuterClass.Add parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.spark.sql.execution.serde.ExprOuterClass.Add) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private org.apache.spark.sql.execution.serde.ExprOuterClass.Expr left_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.execution.serde.ExprOuterClass.Expr, org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.ExprOrBuilder> leftBuilder_;
      /**
       * <code>.spark.spark_expression.Expr left = 1;</code>
       * @return Whether the left field is set.
       */
      public boolean hasLeft() {
        return leftBuilder_ != null || left_ != null;
      }
      /**
       * <code>.spark.spark_expression.Expr left = 1;</code>
       * @return The left.
       */
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Expr getLeft() {
        if (leftBuilder_ == null) {
          return left_ == null ? org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.getDefaultInstance() : left_;
        } else {
          return leftBuilder_.getMessage();
        }
      }
      /**
       * <code>.spark.spark_expression.Expr left = 1;</code>
       */
      public Builder setLeft(org.apache.spark.sql.execution.serde.ExprOuterClass.Expr value) {
        if (leftBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          left_ = value;
          onChanged();
        } else {
          leftBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <code>.spark.spark_expression.Expr left = 1;</code>
       */
      public Builder setLeft(
          org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder builderForValue) {
        if (leftBuilder_ == null) {
          left_ = builderForValue.build();
          onChanged();
        } else {
          leftBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <code>.spark.spark_expression.Expr left = 1;</code>
       */
      public Builder mergeLeft(org.apache.spark.sql.execution.serde.ExprOuterClass.Expr value) {
        if (leftBuilder_ == null) {
          if (left_ != null) {
            left_ =
              org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.newBuilder(left_).mergeFrom(value).buildPartial();
          } else {
            left_ = value;
          }
          onChanged();
        } else {
          leftBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <code>.spark.spark_expression.Expr left = 1;</code>
       */
      public Builder clearLeft() {
        if (leftBuilder_ == null) {
          left_ = null;
          onChanged();
        } else {
          left_ = null;
          leftBuilder_ = null;
        }

        return this;
      }
      /**
       * <code>.spark.spark_expression.Expr left = 1;</code>
       */
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder getLeftBuilder() {
        
        onChanged();
        return getLeftFieldBuilder().getBuilder();
      }
      /**
       * <code>.spark.spark_expression.Expr left = 1;</code>
       */
      public org.apache.spark.sql.execution.serde.ExprOuterClass.ExprOrBuilder getLeftOrBuilder() {
        if (leftBuilder_ != null) {
          return leftBuilder_.getMessageOrBuilder();
        } else {
          return left_ == null ?
              org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.getDefaultInstance() : left_;
        }
      }
      /**
       * <code>.spark.spark_expression.Expr left = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.execution.serde.ExprOuterClass.Expr, org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.ExprOrBuilder> 
          getLeftFieldBuilder() {
        if (leftBuilder_ == null) {
          leftBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.spark.sql.execution.serde.ExprOuterClass.Expr, org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.ExprOrBuilder>(
                  getLeft(),
                  getParentForChildren(),
                  isClean());
          left_ = null;
        }
        return leftBuilder_;
      }

      private org.apache.spark.sql.execution.serde.ExprOuterClass.Expr right_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.execution.serde.ExprOuterClass.Expr, org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.ExprOrBuilder> rightBuilder_;
      /**
       * <code>.spark.spark_expression.Expr right = 2;</code>
       * @return Whether the right field is set.
       */
      public boolean hasRight() {
        return rightBuilder_ != null || right_ != null;
      }
      /**
       * <code>.spark.spark_expression.Expr right = 2;</code>
       * @return The right.
       */
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Expr getRight() {
        if (rightBuilder_ == null) {
          return right_ == null ? org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.getDefaultInstance() : right_;
        } else {
          return rightBuilder_.getMessage();
        }
      }
      /**
       * <code>.spark.spark_expression.Expr right = 2;</code>
       */
      public Builder setRight(org.apache.spark.sql.execution.serde.ExprOuterClass.Expr value) {
        if (rightBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          right_ = value;
          onChanged();
        } else {
          rightBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <code>.spark.spark_expression.Expr right = 2;</code>
       */
      public Builder setRight(
          org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder builderForValue) {
        if (rightBuilder_ == null) {
          right_ = builderForValue.build();
          onChanged();
        } else {
          rightBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <code>.spark.spark_expression.Expr right = 2;</code>
       */
      public Builder mergeRight(org.apache.spark.sql.execution.serde.ExprOuterClass.Expr value) {
        if (rightBuilder_ == null) {
          if (right_ != null) {
            right_ =
              org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.newBuilder(right_).mergeFrom(value).buildPartial();
          } else {
            right_ = value;
          }
          onChanged();
        } else {
          rightBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <code>.spark.spark_expression.Expr right = 2;</code>
       */
      public Builder clearRight() {
        if (rightBuilder_ == null) {
          right_ = null;
          onChanged();
        } else {
          right_ = null;
          rightBuilder_ = null;
        }

        return this;
      }
      /**
       * <code>.spark.spark_expression.Expr right = 2;</code>
       */
      public org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder getRightBuilder() {
        
        onChanged();
        return getRightFieldBuilder().getBuilder();
      }
      /**
       * <code>.spark.spark_expression.Expr right = 2;</code>
       */
      public org.apache.spark.sql.execution.serde.ExprOuterClass.ExprOrBuilder getRightOrBuilder() {
        if (rightBuilder_ != null) {
          return rightBuilder_.getMessageOrBuilder();
        } else {
          return right_ == null ?
              org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.getDefaultInstance() : right_;
        }
      }
      /**
       * <code>.spark.spark_expression.Expr right = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.execution.serde.ExprOuterClass.Expr, org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.ExprOrBuilder> 
          getRightFieldBuilder() {
        if (rightBuilder_ == null) {
          rightBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.spark.sql.execution.serde.ExprOuterClass.Expr, org.apache.spark.sql.execution.serde.ExprOuterClass.Expr.Builder, org.apache.spark.sql.execution.serde.ExprOuterClass.ExprOrBuilder>(
                  getRight(),
                  getParentForChildren(),
                  isClean());
          right_ = null;
        }
        return rightBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.spark_expression.Add)
    }

    // @@protoc_insertion_point(class_scope:spark.spark_expression.Add)
    private static final org.apache.spark.sql.execution.serde.ExprOuterClass.Add DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.sql.execution.serde.ExprOuterClass.Add();
    }

    public static org.apache.spark.sql.execution.serde.ExprOuterClass.Add getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Add>
        PARSER = new com.google.protobuf.AbstractParser<Add>() {
      @java.lang.Override
      public Add parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Add(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Add> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Add> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.Add getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BoundReferenceOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.spark_expression.BoundReference)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>int32 index = 1;</code>
     * @return The index.
     */
    int getIndex();
  }
  /**
   * <pre>
   * Bound to a particular vector array in input batch.
   * </pre>
   *
   * Protobuf type {@code spark.spark_expression.BoundReference}
   */
  public static final class BoundReference extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.spark_expression.BoundReference)
      BoundReferenceOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use BoundReference.newBuilder() to construct.
    private BoundReference(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BoundReference() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new BoundReference();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private BoundReference(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {

              index_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_BoundReference_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_BoundReference_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.class, org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.Builder.class);
    }

    public static final int INDEX_FIELD_NUMBER = 1;
    private int index_;
    /**
     * <code>int32 index = 1;</code>
     * @return The index.
     */
    @java.lang.Override
    public int getIndex() {
      return index_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (index_ != 0) {
        output.writeInt32(1, index_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (index_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, index_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference)) {
        return super.equals(obj);
      }
      org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference other = (org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference) obj;

      if (getIndex()
          != other.getIndex()) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + INDEX_FIELD_NUMBER;
      hash = (53 * hash) + getIndex();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Bound to a particular vector array in input batch.
     * </pre>
     *
     * Protobuf type {@code spark.spark_expression.BoundReference}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.spark_expression.BoundReference)
        org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReferenceOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_BoundReference_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_BoundReference_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.class, org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.Builder.class);
      }

      // Construct using org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        index_ = 0;

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.internal_static_spark_spark_expression_BoundReference_descriptor;
      }

      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference getDefaultInstanceForType() {
        return org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference build() {
        org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference buildPartial() {
        org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference result = new org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference(this);
        result.index_ = index_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference) {
          return mergeFrom((org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference other) {
        if (other == org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference.getDefaultInstance()) return this;
        if (other.getIndex() != 0) {
          setIndex(other.getIndex());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private int index_ ;
      /**
       * <code>int32 index = 1;</code>
       * @return The index.
       */
      @java.lang.Override
      public int getIndex() {
        return index_;
      }
      /**
       * <code>int32 index = 1;</code>
       * @param value The index to set.
       * @return This builder for chaining.
       */
      public Builder setIndex(int value) {
        
        index_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>int32 index = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearIndex() {
        
        index_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.spark_expression.BoundReference)
    }

    // @@protoc_insertion_point(class_scope:spark.spark_expression.BoundReference)
    private static final org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference();
    }

    public static org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<BoundReference>
        PARSER = new com.google.protobuf.AbstractParser<BoundReference>() {
      @java.lang.Override
      public BoundReference parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new BoundReference(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<BoundReference> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<BoundReference> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.spark.sql.execution.serde.ExprOuterClass.BoundReference getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_spark_spark_expression_Expr_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_spark_spark_expression_Expr_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_spark_spark_expression_Literal_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_spark_spark_expression_Literal_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_spark_spark_expression_Add_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_spark_spark_expression_Add_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_spark_spark_expression_BoundReference_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_spark_spark_expression_BoundReference_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\024src/proto/expr.proto\022\026spark.spark_expr" +
      "ession\"\256\001\n\004Expr\0222\n\007literal\030\002 \001(\0132\037.spark" +
      ".spark_expression.LiteralH\000\022*\n\003add\030\003 \001(\013" +
      "2\033.spark.spark_expression.AddH\000\0227\n\005bound" +
      "\030\004 \001(\0132&.spark.spark_expression.BoundRef" +
      "erenceH\000B\r\n\013expr_struct\"\243\001\n\007Literal\022\022\n\010b" +
      "ool_val\030\001 \001(\010H\000\022\021\n\007int_val\030\002 \001(\005H\000\022\022\n\010lo" +
      "ng_val\030\003 \001(\003H\000\022\023\n\tfloat_val\030\004 \001(\002H\000\022\024\n\nd" +
      "ouble_val\030\005 \001(\001H\000\022\024\n\nstring_val\030\006 \001(\tH\000\022" +
      "\023\n\tbytes_val\030\007 \001(\014H\000B\007\n\005value\"^\n\003Add\022*\n\004" +
      "left\030\001 \001(\0132\034.spark.spark_expression.Expr" +
      "\022+\n\005right\030\002 \001(\0132\034.spark.spark_expression" +
      ".Expr\"\037\n\016BoundReference\022\r\n\005index\030\001 \001(\005B&" +
      "\n$org.apache.spark.sql.execution.serdeb\006" +
      "proto3"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
        });
    internal_static_spark_spark_expression_Expr_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_spark_spark_expression_Expr_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_spark_spark_expression_Expr_descriptor,
        new java.lang.String[] { "Literal", "Add", "Bound", "ExprStruct", });
    internal_static_spark_spark_expression_Literal_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_spark_spark_expression_Literal_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_spark_spark_expression_Literal_descriptor,
        new java.lang.String[] { "BoolVal", "IntVal", "LongVal", "FloatVal", "DoubleVal", "StringVal", "BytesVal", "Value", });
    internal_static_spark_spark_expression_Add_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_spark_spark_expression_Add_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_spark_spark_expression_Add_descriptor,
        new java.lang.String[] { "Left", "Right", });
    internal_static_spark_spark_expression_BoundReference_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_spark_spark_expression_BoundReference_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_spark_spark_expression_BoundReference_descriptor,
        new java.lang.String[] { "Index", });
  }

  // @@protoc_insertion_point(outer_class_scope)
}
